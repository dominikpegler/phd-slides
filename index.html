<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Machine Learning for Human-Centered Solutions</title>
<meta name="author" content="Dominik Pegler"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="./reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="./reveal.js/dist/theme/white.css" id="theme"/>

<link rel="stylesheet" href="css/custom.css"/>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<div><h1>Machine Learning for Human-Centered Solutions</h1><h3 style="color:#6b6b6b">Interpretability, Emotion Recognition, and Therapeutic Innovation<h3><p style="text-transform:none;color:black;font-weight:normal">Dominik Pegler<p></div>
</section>
<section>
<section id="slide-orgcc9a098">
<h2 id="orgcc9a098">Overview</h2>
<ul>
<li>Machine Learning to enhance human experience in cognitive and affective domain
<ul>
<li>Cognitive Domain
<ul>
<li>1 – <b>Interpretability of Machine-Generated Solutions</b></li>

</ul></li>
<li>Affective Domain
<ul>
<li>2 – <b>Fear Detection</b></li>
<li>3 – <b>Optimizing Exposure Therapy</b></li>

</ul></li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="slide-orgfb845ad">
<h2 id="orgfb845ad">Project 1</h2>
<p>
<b>INTERPRETABILITY OF MACHINE-GENERATED SOLUTIONS TO COMBINATORIAL DESIGN PROBLEMS</b>
</p>
</section>
<section id="slide-org01ee8a8">
<h3 id="org01ee8a8">Problem Setting</h3>
<aside class="notes">
<p>
Today, I am going to present you a new study on the topic of human-machine colaboration.
</p>

</aside>

<div style="float: left; width: 80%">
<p>
<b>Machine Problem-Solving</b>
</p>
<ul>
<li class="fragment">Increasingly taking over human domains</li>
<li class="fragment">AI getting more complex &rarr; black boxes &rarr; lack of trust</li>
<li class="fragment">Trust issues not new (Classical AI in 1950s)</li>

</ul>
<p class="fragment (t)">
<b>Evaluating Human Interpretability</b>
</p>
<ul>
<li class="fragment">Human-in-the-loop approach to evaluate interpretability</li>
<li class="fragment">Understanding how a machine makes a decision</li>
<li class="fragment">Critical for trust and collaboration with machines</li>

</ul>
</div>

<div style="float: right; width: 20%">

<div id="orgb417e77" class="figure">
<p class="org-p-fig"><img src="./img/dantzig.jpg" alt="dantzig.jpg" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 1: </span>George Dantzig, father of linear programming (Source: <a href="https://malevus.com/george-dantzig">malevus.com</a>).</p>
</div>
</div>
</section>
<section id="slide-org7191f46">
<h3 id="org7191f46">Combinatorial Design Problems</h3>
<div style="display:flex;flex-direction:column;height: 100%">
<div style="display:flex; flex-direction:row;justify-content:space-between;height:40%;">

<div id="org5f729ba" class="figure">
<p class="org-p-fig"><img src="./svg/knapsack.svg" alt="knapsack.svg" class="org-svg" height="180px" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 2: </span>Knapsack Problem (source: <a href="https://commons.wikimedia.org/wiki/File:Knapsack.svg">wikimedia commons</a>).</p>
</div>

<div id="org6c2882d" class="figure">
<p class="org-p-fig"><img src="./svg/traveling_salesman.svg" alt="traveling_salesman.svg" class="org-svg" height="180px" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 3: </span>Traveling Salesman Problem (source: <a href="https://commons.wikimedia.org/wiki/File:GLPK_solution_of_a_travelling_salesman_problem.svg">wikimedia commons</a>).</p>
</div>

<div id="org56c043c" class="figure">
<p class="org-p-fig"><img src="./svg/minimum_spanning_tree.svg" alt="minimum_spanning_tree.svg" class="org-svg" height="180px" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 4: </span>Minimum Spanning Tree Problem (source: <a href="https://commons.wikimedia.org/wiki/File:Minimum_spanning_tree.svg">wikimedia commons</a>).</p>
</div>
</div>
<div style="display:flex;flex-direction:column;max-height:60%">
<ul>
<li class="fragment">Many real-world scenarios (logistics, etc.)</li>
<li class="fragment">Can be solved by machines optimally (e.g., with Linear Programming)</li>
<li class="fragment">Can be solved by humans (if problem is small enough)</li>

</ul>
<p class="fragment (t)">
&rarr; <b><b>Good setting for human-machine collaboration</b></b>
</p>
</div>
</div>
</section>
<section id="slide-org80412c2">
<h3 id="org80412c2">Bin-Packing Problem</h3>
<div style="display:flex;flex-direction:row;width: 100%">
<div style="display:flex; flex-direction:column;justify-content:center;width:70%;">
<ul>
<li>Abstract representation of real-world scenarios (e.g., scheduling)</li>
<li>Pack items into boxes</li>
<li>Goal: Fill the boxes as much as possible</li>
<li>Constraint: You cannot overfill the boxes</li>

</ul>
</div>
<div style="display:flex;flex-direction:column;max-width:30%">

<div id="orgf099425" class="figure">
<p class="org-p-fig"><img src="./img/binpacking.gif" alt="binpacking.gif" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 5: </span>A human performing the bin packing task.</p>
</div>
</div>
</div>
</section>
<section id="slide-org78b6994">
<h3 id="org78b6994">Optimal Solutions</h3>

<div id="org9eab90c" class="figure">
<p class="org-p-fig"><img src="./img/optimalsolutions.gif" alt="optimalsolutions.gif" height="600px" margin-top="0px" margin-bottom="0px" />
</p>
<p class="org-p-figcaption"><span class="figure-number">Figure 6: </span>The machine (<a href="https://developers.google.com/optimization/cp/cp_solver">CP-SAT</a>) providing possible optimal solutions.</p>
</div>
</section>
<section id="slide-org7558f89">
<h3 id="org7558f89">Question</h3>
<p>
<b>"What makes a solution interpretable?"</b>
</p>
</section>
<section id="slide-org25afc90" data-auto-animate>
<h3 id="org25afc90">Hypotheses</h3>
<p>
<b>H1: Heuristic</b>
</p>
<ul>
<li>Humans use heuristics to solve these problems, i.e., a greedy heuristic</li>
<li>&#x2026;</li>
<li><b>&rarr; Solutions more interpretable the more similar they are to the greedy solution</b></li>

</ul>
</section>
<section id="slide-org52bfc9e" data-auto-animate>
<h3 id="org52bfc9e">Hypotheses</h3>
<p>
<b>H2: Simplicity</b>
</p>

<ul>
<li>&#x2026;</li>
<li>&#x2026;</li>
<li><b>&rarr; Solutions more interpretable the simpler they are</b></li>

</ul>
</section>
<section id="slide-org2ad4959" data-auto-animate>
<h3 id="org2ad4959">Hypotheses</h3>
<p>
<b>H3: Representation</b>
</p>

<ul>
<li>Focus on order</li>
<li>Items and boxes can be sorted by size or at random</li>
<li><b>&rarr; Solutions more interpretable if they sorted</b></li>

</ul>
</section>
<section id="slide-org1c2a878" data-auto-animate>
<h3 id="org1c2a878">Experiment</h3>
<ul>
<li>here an overview</li>
<li>of the</li>
<li>experiment</li>
<li>&#x2026;</li>

</ul>
</section>
<section id="slide-orgf8e3a3a" data-auto-animate>
<h3 id="orgf8e3a3a">Experiment</h3>
<ul>
<li>here a more detailed view of the evaluation trials</li>

</ul>
</section>
<section id="slide-orga8a5999">
<h3 id="orga8a5999">Results</h3>
</section>
<section id="slide-orgb32b6b9">
<h3 id="orgb32b6b9">Limitations</h3>
</section>
<section id="slide-org34b167e">
<h3 id="org34b167e">Takeaways</h3>
</section>
</section>
<section>
<section id="slide-org2bd2551">
<h2 id="org2bd2551">Project 2</h2>
<p>
<b>LEARNING AND LOCALIZING FEAR WITH COMPUTER VISION MODELS</b>
</p>
</section>
<section id="slide-orge0c0a91">
<h3 id="orge0c0a91">Problem Setting</h3>
<ul>
<li>Exposure therapy research</li>
<li>Aim: computer-aided exposure therapy</li>
<li>Focus on spider phobia</li>
<li>Stimuli = images
<ul>
<li>Information needed, e.g., how much fear they provoke</li>
<li>we collected for a set of around 300 spider images fear ratings</li>

</ul></li>
<li>Problem: Number of stimuli limited (300)
<ul>
<li>constantly collecting new fear ratings for each new stimulus not
feasible</li>

</ul></li>

</ul>
</section>
<section id="slide-org3c60a27">
<h3 id="org3c60a27">Deep Neural Networks</h3>
<ul>
<li>Solution: Deep neural networks create larger stimulus sets (<a href="#citeproc_bib_item_1">LeCun et al., 2015</a>)</li>
<li>Train them on old data (300 images with fear ratings) so that
they can give you a fear rating for any new image</li>

</ul>
</section>
<section id="slide-org2ca17ef">
<h3 id="org2ca17ef">Additional Use Cases</h3>
<ul>
<li>Content Management</li>
<li>Alignment Research</li>

</ul>
</section>
</section>
<section>
<section id="slide-org0da056e">
<h2 id="org0da056e">Project 3</h2>
<p>
<b>LEARNING OPTIMAL EXPOSURE THERAPY PROTOCOLS WITH REINFORCEMENT LEARNING</b>
</p>
</section>
<section id="slide-org3bf42ae">
<h3 id="org3bf42ae">Problem Setting</h3>
<ul>
<li>Reinforcement Learning (RL; <a href="#citeproc_bib_item_2">Sutton &#38; Barto, 2018</a>)</li>

</ul>
</section>
</section>
<section>
<section id="slide-bibliography">
<h2 id="bibliography">References</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>LeCun, Y., Bengio, Y., &#38; Hinton, G. (2015). Deep learning. <i>Nature</i>, <i>521</i>(7553, 7553), 436–444. <a href="https://doi.org/10.1038/nature14539">https://doi.org/10.1038/nature14539</a></div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Sutton, R. S., &#38; Barto, A. G. (2018). <i>Reinforcement learning: An introduction, 2nd ed.</i> (p. xxii, 526). The MIT Press.</div>
</div>
</section>
</section>
</div>
</div>
<script src="./reveal.js/dist/reveal.js"></script>
<script src="./reveal.js/plugin/markdown/markdown.js"></script>
<script src="./reveal.js/plugin/notes/notes.js"></script>
<script src="./reveal.js/plugin/search/search.js"></script>
<script src="./reveal.js/plugin/zoom/zoom.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 't',
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,
width: 1200,
height: 800,
margin: 0.10,

transition: 'slide',
transitionSpeed: 'fast',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom ],

// Optional libraries used to extend reveal.js
dependencies: [
]

});
</script>
</body>
</html>
